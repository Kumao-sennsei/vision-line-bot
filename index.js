// ==========================
// ğŸ“¦ vision-line-bot index.js
// Turbo + Cloudinary + Vision APIå¯¾å¿œ
// ==========================

import express from 'express';
import line from '@line/bot-sdk';
import dotenv from 'dotenv';
import axios from 'axios';
import FormData from 'form-data';
import { v2 as cloudinary } from 'cloudinary';
import { OpenAI } from 'openai';

dotenv.config();

// LINEè¨­å®š
const config = {
  channelAccessToken: process.env.LINE_CHANNEL_ACCESS_TOKEN,
  channelSecret: process.env.LINE_CHANNEL_SECRET
};
const client = new line.Client(config);
const app = express();

// Cloudinaryè¨­å®š
cloudinary.config({
  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
  api_key: process.env.CLOUDINARY_API_KEY,
  api_secret: process.env.CLOUDINARY_API_SECRET
});

// OpenAIè¨­å®š
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.post('/webhook', line.middleware(config), async (req, res) => {
  const events = req.body.events;
  for (const event of events) {
    if (event.type !== 'message') continue;

    // â‘  ç”»åƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
    if (event.message.type === 'image') {
      try {
        await client.replyMessage(event.replyToken, {
          type: 'text',
          text: 'ç”»åƒã®å‡¦ç†ä¸­ã§ã™ãƒ»ãƒ»ãƒ»'
        });

        const stream = await client.getMessageContent(event.message.id);
        const chunks = [];
        for await (const chunk of stream) chunks.push(chunk);
        const buffer = Buffer.concat(chunks);

        const uploadRes = await cloudinary.uploader.upload_stream({ resource_type: 'image' }, async (error, result) => {
          if (error) throw error;

          const imageUrl = result.secure_url;

          // â‘¡ Vision APIã§ç”»åƒè§£æ
          const visionRes = await openai.chat.completions.create({
            model: 'gpt-4-vision-preview',
            messages: [
              {
                role: 'system',
                content: 'ã‚ãªãŸã¯å„ªã—ãã¦é¢ç™½ã„æ•°å­¦ã®å…ˆç”Ÿã€Œãã¾ãŠå…ˆç”Ÿã€ã§ã™ã€‚ç”»åƒã®è³ªå•ã«ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚'
              },
              {
                role: 'user',
                content: [
                  {
                    type: 'image_url',
                    image_url: { url: imageUrl }
                  },
                  {
                    type: 'text',
                    text: 'ã“ã®ç”»åƒã®å†…å®¹ã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„'
                  }
                ]
              }
            ],
            max_tokens: 1000
          });

          const reply = visionRes.choices[0].message.content || 'ã†ãƒ¼ã‚“ã€ã¡ã‚‡ã£ã¨åˆ†ã‹ã‚‰ãªã„ã‹ã‚‚â€¦';
          await client.pushMessage(event.source.userId, { type: 'text', text: reply });
        });

        const passthrough = uploadRes;
      } catch (e) {
        console.error(e);
        await client.replyMessage(event.replyToken, {
          type: 'text',
          text: 'ç”»åƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚'
        });
      }
    }

    // â‘¡ ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
    else if (event.message.type === 'text') {
      try {
        const text = event.message.text;
        const response = await openai.chat.completions.create({
          model: 'gpt-4-turbo',
          messages: [
            { role: 'system', content: 'ã‚ãªãŸã¯å„ªã—ãã¦é¢ç™½ã„å…ˆç”Ÿã€Œãã¾ãŠå…ˆç”Ÿã€ã§ã™ã€‚è³ªå•ã«åˆ†ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚' },
            { role: 'user', content: text }
          ],
          max_tokens: 1000
        });

        const reply = response.choices[0].message.content;
        await client.replyMessage(event.replyToken, { type: 'text', text: reply });
      } catch (err) {
        console.error(err);
        await client.replyMessage(event.replyToken, {
          type: 'text',
          text: 'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å°‘ã—æ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚'
        });
      }
    }
  }
  res.status(200).send('OK');
});

const port = process.env.PORT || 3000;
app.listen(port, () => console.log(`ğŸš€ Server running on port ${port}`));
